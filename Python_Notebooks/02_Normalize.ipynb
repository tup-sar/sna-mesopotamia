{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developed by Carlos Gonçalves, with funding from the São Paulo State Foundation - FAPESP, Grant 2021/01363-6\n",
    "# See README for more information\n",
    "#\n",
    "# This is the second of four scripts.\n",
    "#\n",
    "# It produces a file calles normalized_names+run_date.txt from the file generate by 01_parsing script (the file is called\n",
    "# \"parsing\"+run_date_out+\".txt\", where run_date_out is the date when parsing was run). \n",
    "# There are two differences between the two files:\n",
    "# - the personal names appear in transliterated form in parsing.txt, while they appear in normalized form\n",
    "# in normalized_names.txt. For instance, nu-ur2-utu is replaced by Nūr-Šamaš.\n",
    "# - besides, if the file identities.txt is not empty, this script replaces the identification as written in \n",
    "# the the cuneiform tablets by the one specified in identities.txt. This is used to resolve ambiguitites in \n",
    "# the original documentation, and it does involve a degree of interpretation, so it must be used with caution.\n",
    "#\n",
    "# Input files:\n",
    "# ../Processing_Input/names+names_date+.txt\n",
    "# ../Processing_Output/parsint_run_date_in+.txt\n",
    "# ..Processing_Input/identities+identities_date+.txt\n",
    "# Output file:\n",
    "# ../Processing_output/normalized_names+run_date_out+.txt\n",
    "\n",
    "\n",
    "\n",
    "run_date_in = '_2023_12_05'\n",
    "\n",
    "run_date_out = '_2023_12_05'\n",
    "\n",
    "names_date = '_2023_03_13'\n",
    "identities_date = '_2023_03_14'\n",
    "base_folder = \"..\"\n",
    "\n",
    "\n",
    "import io\n",
    "f = io.open(base_folder+\"/Processing_Input/names\"+names_date+\".txt\",'r', encoding = \"utf-8\")\n",
    "g = io.open(base_folder+\"/Processing_Output/parsing\"+run_date_in+\".txt\",'r', encoding = \"utf-8\")\n",
    "h = io.open(base_folder+\"/Processing_Output/normalized_names\"+run_date_out+\".txt\",\"w\", encoding = \"utf-8\")\n",
    "glossario = {}\n",
    "\n",
    "# Here I load the rules for replacing names in order to solve homonyms and aliases\n",
    "# This is far from being the most elegant solution, but it seemed to me that (under the excruciating pressure \n",
    "# of time), it could be easily implemented. So,\n",
    "# - any resolution of homonyms of aliases must be manually included in the file identities.txt\n",
    "# - the file does not distinguish if the originaly problem derives from homonyms of from aliases\n",
    "# - all solution have the same format:\n",
    "# -- in each line, we identify a transliteration, a doc number and a face.line and we state how\n",
    "#    this should be normalized\n",
    "# \n",
    "# All in all, this script makes two different although associated things:\n",
    "# - it replaces for a given transliteration a correct normalisation\n",
    "# - it complements the normalisation in order to solve homonyms and aliases\n",
    "# For instance:\n",
    "# - it normalises J-o-h-n and I-o-h-n as John\n",
    "# - it may (if this makes sense to the human operating the system) change John to John, \n",
    "#   the carpenter, son of Joseph, reuniting all the occurrences of the same person under one only of their aliases\n",
    "# - it may also change indicate the John in certain tablets is in reality John 2, because there are two \n",
    "#   people with this name in the community\n",
    "\n",
    "\n",
    "\n",
    "i = io.open(base_folder+\"/Processing_Input/identities\"+identities_date+\".txt\",\"r\", encoding = \"utf-8\")\n",
    "replacements = {}\n",
    "for line in i:\n",
    "    if (line[0] == \"#\"):\n",
    "        continue\n",
    "    line = line.strip()\n",
    "    linha_quebrada = line.split('|')\n",
    "    #print(line, linha_quebrada)\n",
    "    replacements[linha_quebrada[0],linha_quebrada[1],linha_quebrada[2]] = [linha_quebrada[3],linha_quebrada[4],linha_quebrada[5],linha_quebrada[6]]\n",
    "#print(replacements)\n",
    "\n",
    "#for chave in replacements:\n",
    "#    print(chave, replacements[chave])\n",
    "\n",
    "\n",
    "for line in f:\n",
    "    linha_quebrada = line.split('\\t')\n",
    "    glossario[linha_quebrada[2]] = linha_quebrada[1]\n",
    "f.close()\n",
    "count_unknown = 1\n",
    "for line in g:\n",
    "    line = line.replace(\"{d}\",\"\")\n",
    "    line = line.replace(\"{disz}\",\"\")\n",
    "    linha_quebrada = line.split(\"|&\")\n",
    "# is this a homonym or alias that must be replaced?\n",
    "    nominho = (linha_quebrada[0], linha_quebrada[5], linha_quebrada[6]+linha_quebrada[7])\n",
    "    #print(nominho)\n",
    "    if nominho in replacements:\n",
    "        replacement_case = True\n",
    "    else:\n",
    "        replacement_case = False\n",
    "        \n",
    "        \n",
    "        # replacing the profession\n",
    "\n",
    "    nome = linha_quebrada[0]\n",
    "    if (nome !=''):\n",
    "        if(replacement_case):\n",
    "            # replacing the name from list of homonyms and aliases\n",
    "            nome_normalisado = replacements[nominho][0]\n",
    "        else:\n",
    "            nome_normalisado = glossario[nome]\n",
    "        if (nome_normalisado != ''):\n",
    "            linha_quebrada[0] = nome_normalisado\n",
    "            if (nome_normalisado == 'Unknown'):\n",
    "                linha_quebrada[0] = nome_normalisado + '_' + str(count_unknown)+ '('+ nome +')'\n",
    "                count_unknown = count_unknown + 1\n",
    "                \n",
    "    if(replacement_case):\n",
    "        # replacing the kinship\n",
    "        linha_quebrada[1] = replacements[nominho][1]\n",
    "        \n",
    "    nome = linha_quebrada[2]\n",
    "    if ((nome !='') or (replacement_case)):\n",
    "        if(replacement_case):\n",
    "        # replacing the relative\n",
    "            nome_normalisado = replacements[nominho][2]\n",
    "        else:\n",
    "            nome_normalisado = glossario[nome]\n",
    "        if(nome_normalisado !=''):\n",
    "            linha_quebrada[2] = nome_normalisado\n",
    "            if (nome_normalisado == 'Unknown'):\n",
    "                linha_quebrada[2] = nome_normalisado + '_' + str(count_unknown) + '('+ nome +')'\n",
    "                count_unknown = count_unknown + 1\n",
    "    \n",
    "    if(replacement_case):\n",
    "        # replacing profession\n",
    "        linha_quebrada[3] = replacements[nominho][3]\n",
    "    \n",
    "    \n",
    "    #print(linha_quebrada)\n",
    "    \n",
    "    h.write('|'.join(map(str, linha_quebrada)))\n",
    "g.close()\n",
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
